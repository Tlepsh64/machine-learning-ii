{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection with cross-validation\n",
    "\n",
    "In the following, we explain how 10-fold cross-validation can be used to estimate the variance of model parameters:\n",
    "\n",
    "* During the training phase, model parameters are fixed.\n",
    "* Depending on the training data, we can get very different parameter values.\n",
    "* Training set size is appropriate if parameter values are roughly the same for most training sets.\n",
    "* If a model parameter has large variablility over the training sets, it cannot be trusted.\n",
    "\n",
    "Note that for some models, comparing parameters does not make sense as the same prediction function can be achieved with many parameter values.\n",
    "For instance, neural networks have permutation symmetries – predictions do not change if we change the order of neurons in hidden layers.\n",
    "Thus, estimators of parameter variance make sense only for models that have compact representations – two different parameter sets determine two different predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm import tnrange#, tqdm_notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Experiment setup\n",
    "\n",
    "We again consider a relatively simple prediction task with a relatively small feature set and an impossible prediction task with the same feature set for comparison. \n",
    "We use majority voting and logistic regression as example classifiers as in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_0 = lambda n: data_sampler(n, 8, lambda x: logit(x, Series([0, 0])))\n",
    "sampler_1 = lambda n: data_sampler(n, 8, lambda x: logit(x, Series([1, 1])))\n",
    "clf_1 = MajorityVoting()\n",
    "clf_2 = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modified cross-validation algorithm\n",
    "\n",
    "We will use the standard cross-validation scheme but instead of measuring test and training errors, we collect model parameters:\n",
    "* For majority voting, the parameter set is the prediction table.\n",
    "* For logistic regression, the parameter set comprises model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "m = 10\n",
    "n = k * m\n",
    "data = sampler_1(n)\n",
    "features = list(data.columns.values[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing cross-validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation_splits(X: DataFrame, y: Series, k: int=10) -> Tuple[List[int], List[int]]:\n",
    "    assert len(X) == len(y), 'Data matrix and the target vector must match'\n",
    "    assert len(X) % k == 0,  'Crossvalidation is unimplemented for cases n != k * m'  \n",
    "    assert X.index.equals(y.index), 'Indices of the data matrix and target vector must match'\n",
    "\n",
    "    n = len(X)\n",
    "    m = int(n/k)\n",
    "    samples = np.random.permutation(X.index)\n",
    "    folds = [samples[start: start + m] for start in range(0, n, m)]\n",
    "    \n",
    "    for i in range(k):\n",
    "        training_index = [x for x in range(k) if x != i]\n",
    "        training_samples = np.concatenate([folds[i] for i in training_index])\n",
    "        test_samples = folds[i]\n",
    "        yield (i, training_samples, test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Way to extract coefficients of logistic regression model\n",
    "\n",
    "Logistic regression model has coefficients $\\boldsymbol{\\beta}=(\\beta_1,\\ldots,\\beta_m)$ and a free term $\\beta_0$.\n",
    "The following code shows how to extract them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06385959]\n",
      "[[ 0.86000517  0.36505967  0.00729999 -0.08438129  0.37976109 -0.88904146\n",
      "   0.18992377 -0.24981471]]\n"
     ]
    }
   ],
   "source": [
    "clf_2.fit(data[features], data['y'])\n",
    "print(clf_2.intercept_)\n",
    "print(clf_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff(clf)->Series:\n",
    "    assert isinstance(clf, sklearn.linear_model._logistic.LogisticRegression), \"Works only for logistic regression\"\n",
    "    return Series(clf.intercept_).append(Series(clf.coef_[0])).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.063860\n",
       "1    0.860005\n",
       "2    0.365060\n",
       "3    0.007300\n",
       "4   -0.084381\n",
       "5    0.379761\n",
       "6   -0.889041\n",
       "7    0.189924\n",
       "8   -0.249815\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff(clf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient variance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run cross-validaton to get different $\\boldsymbol{\\beta}$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>beta_3</th>\n",
       "      <th>beta_4</th>\n",
       "      <th>beta_5</th>\n",
       "      <th>beta_6</th>\n",
       "      <th>beta_7</th>\n",
       "      <th>beta_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087558</td>\n",
       "      <td>0.865362</td>\n",
       "      <td>0.350025</td>\n",
       "      <td>0.015814</td>\n",
       "      <td>-0.102663</td>\n",
       "      <td>0.409723</td>\n",
       "      <td>-0.943250</td>\n",
       "      <td>0.197847</td>\n",
       "      <td>-0.263948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.015910</td>\n",
       "      <td>0.885803</td>\n",
       "      <td>0.270360</td>\n",
       "      <td>0.048607</td>\n",
       "      <td>0.184120</td>\n",
       "      <td>0.513116</td>\n",
       "      <td>-0.913799</td>\n",
       "      <td>0.113338</td>\n",
       "      <td>-0.246498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.167907</td>\n",
       "      <td>0.940724</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>-0.004691</td>\n",
       "      <td>-0.016823</td>\n",
       "      <td>0.311113</td>\n",
       "      <td>-0.968877</td>\n",
       "      <td>0.483920</td>\n",
       "      <td>-0.261836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069937</td>\n",
       "      <td>1.038675</td>\n",
       "      <td>0.157110</td>\n",
       "      <td>-0.089304</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.440259</td>\n",
       "      <td>-0.821025</td>\n",
       "      <td>-0.003229</td>\n",
       "      <td>-0.149791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.771515</td>\n",
       "      <td>0.635581</td>\n",
       "      <td>-0.217343</td>\n",
       "      <td>-0.261234</td>\n",
       "      <td>0.396966</td>\n",
       "      <td>-0.670439</td>\n",
       "      <td>0.315970</td>\n",
       "      <td>-0.253160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211065</td>\n",
       "      <td>0.687686</td>\n",
       "      <td>0.322424</td>\n",
       "      <td>-0.040505</td>\n",
       "      <td>-0.179011</td>\n",
       "      <td>0.388660</td>\n",
       "      <td>-0.849718</td>\n",
       "      <td>0.345064</td>\n",
       "      <td>-0.246101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.660140</td>\n",
       "      <td>0.254506</td>\n",
       "      <td>-0.055107</td>\n",
       "      <td>-0.054048</td>\n",
       "      <td>0.551038</td>\n",
       "      <td>-0.961608</td>\n",
       "      <td>0.247381</td>\n",
       "      <td>-0.128757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.942801</td>\n",
       "      <td>0.420047</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>0.302890</td>\n",
       "      <td>-0.901800</td>\n",
       "      <td>0.060431</td>\n",
       "      <td>-0.124359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.085552</td>\n",
       "      <td>0.812338</td>\n",
       "      <td>0.361997</td>\n",
       "      <td>0.193310</td>\n",
       "      <td>-0.052911</td>\n",
       "      <td>0.179063</td>\n",
       "      <td>-0.837607</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>-0.359197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.373626</td>\n",
       "      <td>0.892671</td>\n",
       "      <td>0.410701</td>\n",
       "      <td>0.210038</td>\n",
       "      <td>-0.245644</td>\n",
       "      <td>0.245549</td>\n",
       "      <td>-0.902717</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>-0.493874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     beta_0    beta_1    beta_2    beta_3    beta_4    beta_5    beta_6  \\\n",
       "0  0.087558  0.865362  0.350025  0.015814 -0.102663  0.409723 -0.943250   \n",
       "1 -0.015910  0.885803  0.270360  0.048607  0.184120  0.513116 -0.913799   \n",
       "2 -0.167907  0.940724  0.430404 -0.004691 -0.016823  0.311113 -0.968877   \n",
       "3  0.069937  1.038675  0.157110 -0.089304  0.010429  0.440259 -0.821025   \n",
       "4  0.056186  0.771515  0.635581 -0.217343 -0.261234  0.396966 -0.670439   \n",
       "5  0.211065  0.687686  0.322424 -0.040505 -0.179011  0.388660 -0.849718   \n",
       "6  0.020348  0.660140  0.254506 -0.055107 -0.054048  0.551038 -0.961608   \n",
       "7  0.023645  0.942801  0.420047 -0.027273 -0.118719  0.302890 -0.901800   \n",
       "8  0.085552  0.812338  0.361997  0.193310 -0.052911  0.179063 -0.837607   \n",
       "9  0.373626  0.892671  0.410701  0.210038 -0.245644  0.245549 -0.902717   \n",
       "\n",
       "     beta_7    beta_8  \n",
       "0  0.197847 -0.263948  \n",
       "1  0.113338 -0.246498  \n",
       "2  0.483920 -0.261836  \n",
       "3 -0.003229 -0.149791  \n",
       "4  0.315970 -0.253160  \n",
       "5  0.345064 -0.246101  \n",
       "6  0.247381 -0.128757  \n",
       "7  0.060431 -0.124359  \n",
       "8  0.074312 -0.359197  \n",
       "9  0.034586 -0.493874  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = (DataFrame(index =list(range(10)))\n",
    "    .reindex(columns = ['beta_{}'.format(i) for i in range(9)]))\n",
    "\n",
    "for i, training_samples, test_samples in crossvalidation_splits(data, data['y']):\n",
    "    train = data.iloc[training_samples]\n",
    "    clf_2.fit(train[features], train['y'])\n",
    "    result.loc[i, :] = coeff(clf_2).values\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Let's melt the data and compute $95\\%$ confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_0</td>\n",
       "      <td>0.087558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_1</td>\n",
       "      <td>0.865362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_2</td>\n",
       "      <td>0.350025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_3</td>\n",
       "      <td>0.015814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_4</td>\n",
       "      <td>-0.102663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold coefficient     value\n",
       "0     0      beta_0  0.087558\n",
       "1     0      beta_1  0.865362\n",
       "2     0      beta_2  0.350025\n",
       "3     0      beta_3  0.015814\n",
       "4     0      beta_4 -0.102663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beta_0</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.141903</td>\n",
       "      <td>-0.060211</td>\n",
       "      <td>0.209031</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta_1</td>\n",
       "      <td>0.849771</td>\n",
       "      <td>0.118204</td>\n",
       "      <td>0.737633</td>\n",
       "      <td>0.961910</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta_2</td>\n",
       "      <td>0.361315</td>\n",
       "      <td>0.128627</td>\n",
       "      <td>0.239289</td>\n",
       "      <td>0.483342</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_3</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.126772</td>\n",
       "      <td>-0.116912</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beta_4</td>\n",
       "      <td>-0.083650</td>\n",
       "      <td>0.131361</td>\n",
       "      <td>-0.208271</td>\n",
       "      <td>0.040970</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beta_5</td>\n",
       "      <td>0.373838</td>\n",
       "      <td>0.115766</td>\n",
       "      <td>0.264013</td>\n",
       "      <td>0.483663</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>beta_6</td>\n",
       "      <td>-0.877084</td>\n",
       "      <td>0.088642</td>\n",
       "      <td>-0.961177</td>\n",
       "      <td>-0.792991</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beta_7</td>\n",
       "      <td>0.186962</td>\n",
       "      <td>0.158851</td>\n",
       "      <td>0.036262</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beta_8</td>\n",
       "      <td>-0.252752</td>\n",
       "      <td>0.111665</td>\n",
       "      <td>-0.358687</td>\n",
       "      <td>-0.146817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coefficient      mean       std  lower_ci  upper_ci  significant\n",
       "0      beta_0  0.074410  0.141903 -0.060211  0.209031        False\n",
       "1      beta_1  0.849771  0.118204  0.737633  0.961910         True\n",
       "2      beta_2  0.361315  0.128627  0.239289  0.483342         True\n",
       "3      beta_3  0.003355  0.126772 -0.116912  0.123622        False\n",
       "4      beta_4 -0.083650  0.131361 -0.208271  0.040970        False\n",
       "5      beta_5  0.373838  0.115766  0.264013  0.483663         True\n",
       "6      beta_6 -0.877084  0.088642 -0.961177 -0.792991         True\n",
       "7      beta_7  0.186962  0.158851  0.036262  0.337662         True\n",
       "8      beta_8 -0.252752  0.111665 -0.358687 -0.146817         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (DataFrame(result.stack(), columns = ['value'])\n",
    "      .reset_index()\n",
    "      .rename(columns = {'level_0':'fold', 'level_1':'coefficient'}))\n",
    "display(head(df))\n",
    "\n",
    "sdf = (df.groupby(['coefficient'])\n",
    "       .aggregate({'value': ['mean', 'std']})\n",
    "       .pipe(reset_column_index, 0)\n",
    "       .assign(lower_ci = lambda df: df['mean'] - 3 * df['std']/np.sqrt(10))\n",
    "       .assign(upper_ci = lambda df: df['mean'] + 3 * df['std']/np.sqrt(10))\n",
    "       .assign(significant = lambda df: np.sign(df['lower_ci'] * df['upper_ci']) == 1)\n",
    "       .reset_index())\n",
    "display(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8763546814314)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = ggplot(df)\n",
    "p = p + geom_hline(yintercept = 0, color = 'red', linetype ='--')\n",
    "p = p + geom_boxplot(aes(x = 'coefficient', y = 'value'), fill = 'oldlace')\n",
    "p = p + scale_x_discrete(name = '', labels=[r'$\\beta_{}$'.format(i) for i in range(9)])\n",
    "p = p + scale_y_continuous(name = \"\", limits = (-1.5, 1.5))\n",
    "p.save('crossvalidation_parameter_variance_i.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223363273307709475)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = ggplot(sdf)\n",
    "p = p + geom_hline(yintercept = 0, color = 'red', linetype ='--', size = 1)\n",
    "p = p + geom_pointrange(aes(x = 'coefficient', ymin = 'lower_ci', y='mean', ymax = 'upper_ci', color = 'significant'), size=0.75)\n",
    "p = p + scale_x_discrete(name = '', labels=[r'$\\beta_{}$'.format(i) for i in range(9)])\n",
    "p = p + scale_y_continuous(name = \"\", limits = (-1.5, 1.5))\n",
    "p = p + scale_color_discrete(guide = False)\n",
    "p.save('crossvalidation_parameter_variance_ii.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Analysis of prediction stability (<font color='red'>3p</font>)\n",
    "\n",
    "Cross-validation can be used to study the stability of a learning algorithm:\n",
    "\n",
    "* You can study how much the coefficients of your model vary.\n",
    "* You can study how fragile is your learning algorithm to noise.\n",
    "\n",
    "Let's explore these concepts by studying the stability of polynomial regression models $y\\sim x^2+x+1$ and $y\\sim x^8 + x^7 + \\cdots + x + 1$.\n",
    "\n",
    "* Stability of coefficients (<font color='red'>1p</font>) \n",
    "  * Fit these models on cross-validation folds and observe regression coefficients by drawing corresponding boxplots. \n",
    "  * Study the mean and variance of individual model coefficients. Declare that a coefficient is insignificant and set it to zero when its mean is not more than 3 standard deviations away from zero. \n",
    "  * Interpret the results. Are both models similar?\n",
    "  \n",
    "  \n",
    "* Stability of predictions (<font color='red'>1p</font>) \n",
    "  * Fit these models on cross-validation folds.\n",
    "  * For each learned model, compute a prediction line in the interval $[-2,1]$.\n",
    "  * Draw a faceted plot with facets for models $y\\sim x^2+x+1$ and $y\\sim x^8 + x^7 + \\cdots + x + 1$.\n",
    "  * On each subplot, plot individual prediction lines. Use `alpha=0.5` to make lines semi-transparent.\n",
    "  * Draw also the average prediction line in red on the plot.\n",
    "\n",
    "\n",
    "* Stability against noise (<font color='red'>1p</font>) \n",
    "  * To study robustness against noise, you can add additional Gaussian noise to $y_i$ values of training samples  and later estimate how much the mean squared error increased as a consequence. \n",
    "  * The latter should estimate how sensitive is your method to random noise.\n",
    "  * Experiment with different scale values $\\sigma=0.001, 0.01, 0.1, 1$, and visualise the results.\n",
    " \n",
    "  \n",
    "\n",
    "### Remarks\n",
    "* Use the sampler `regr_sampler` as the data source. \n",
    "* Use [sklearn.linear_model.LinearRegression](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) together with \n",
    "[sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) to implement polynomial regression:\n",
    "  * First define additional columns $x_2=x^2, \\ldots, x_8=x^8$.\n",
    "  * Then use linear regression to find corresponding coefficients $\\beta_0,\\beta_1,\\ldots, \\beta_8$.\n",
    "* Use [numpy.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html) to sample the additional Gaussian noise needed in the last part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
