{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection with crossvalidation\n",
    "\n",
    "In the following we explain how 10-fold crossvalidation can be used to estimate the variance of model parameters:\n",
    "\n",
    "* During the training phase model parameters are fixed \n",
    "* Depending on the training data we can get very different parameter values\n",
    "* Training set size is appropriate if parameter values are roughly the same for most training sets\n",
    "* If a model parameter has large variablility over the training sets it cannot be trusted \n",
    "\n",
    "Note that for some models comparing parameters does not make sense, as the same prediction function can be achieved with many parameter values.\n",
    "For instance, neural networks have permutation symmetries -- predictions do not change if we change the order of neurons in hidden layers.\n",
    "Thus, estimators of parameter variance make sense only for models that have compact representation -- two different parameter sets determine two different predictors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm import tnrange#, tqdm_notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Experiment setup\n",
    "\n",
    "We again consider a relatively simple prediction task with a relatively small feature set and an impossible prediction task with the same feature set for comparison. \n",
    "We use majority voting and logistic regression as example classifiers as in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_0 = lambda n: data_sampler(n, 8, lambda x: logit(x, Series([0, 0])))\n",
    "sampler_1 = lambda n: data_sampler(n, 8, lambda x: logit(x, Series([1, 1])))\n",
    "clf_1 = MajorityVoting()\n",
    "clf_2 = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modified crossvalidation algorithm\n",
    "\n",
    "We will use standard crossvalidation scheme but instead of measuring test and training errors we collect model paramaters:\n",
    "* For majority voting, the parameter set is the predictin table\n",
    "* For logistic regression, the parameter set are model coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "m = 10\n",
    "n = k * m\n",
    "data = sampler_1(n)\n",
    "features = list(data.columns.values[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing crossvalidation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation_splits(X: DataFrame, y: Series, k: int=10) -> Tuple[List[int], List[int]]:\n",
    "    assert len(X) == len(y), 'Data matrix and the target vector must match'\n",
    "    assert len(X) % k == 0,  'Crossvalidation is unimplemented for cases n != k * m'  \n",
    "    assert X.index.equals(y.index), 'Indices of the data matrix and target vector must match'\n",
    "\n",
    "    n = len(X)\n",
    "    m = int(n/k)\n",
    "    samples = np.random.permutation(X.index)\n",
    "    folds = [samples[start: start + m] for start in range(0, n, m)]\n",
    "    \n",
    "    for i in range(k):\n",
    "        training_index = [x for x in range(k) if x != i]\n",
    "        training_samples = np.concatenate([folds[i] for i in training_index])\n",
    "        test_samples = folds[i]\n",
    "        yield (i, training_samples, test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Way to extract coefficient of logistic regression model\n",
    "\n",
    "Logistic regression model has coefficients $\\boldsymbol{\\beta}=(\\beta_1,\\ldots,\\beta_m)$ and free term $\\beta_0$.\n",
    "The following code shows how one can extract them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83468645]\n",
      "[[ 1.20429275  0.08225427  0.17357964  0.09219616  0.15071062 -0.32913553\n",
      "   0.34991782 -0.09709014]]\n"
     ]
    }
   ],
   "source": [
    "clf_2.fit(data[features], data['y'])\n",
    "print(clf_2.intercept_)\n",
    "print(clf_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff(clf)->Series:\n",
    "    assert isinstance(clf, sklearn.linear_model.logistic.LogisticRegression), \"Works only for logistic regression\"\n",
    "    return Series(clf.intercept_).append(Series(clf.coef_[0])).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.834686\n",
       "1    1.204293\n",
       "2    0.082254\n",
       "3    0.173580\n",
       "4    0.092196\n",
       "5    0.150711\n",
       "6   -0.329136\n",
       "7    0.349918\n",
       "8   -0.097090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff(clf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient variance estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we run crossvalidaton to get different $\\boldsymbol{\\beta}$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>beta_3</th>\n",
       "      <th>beta_4</th>\n",
       "      <th>beta_5</th>\n",
       "      <th>beta_6</th>\n",
       "      <th>beta_7</th>\n",
       "      <th>beta_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.856691</td>\n",
       "      <td>1.207087</td>\n",
       "      <td>0.091872</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.147427</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>-0.616495</td>\n",
       "      <td>0.281108</td>\n",
       "      <td>0.129503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.120037</td>\n",
       "      <td>1.239479</td>\n",
       "      <td>0.110921</td>\n",
       "      <td>0.302168</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>0.171504</td>\n",
       "      <td>-0.329141</td>\n",
       "      <td>0.306554</td>\n",
       "      <td>0.025916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.552030</td>\n",
       "      <td>1.249885</td>\n",
       "      <td>0.030376</td>\n",
       "      <td>0.103642</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>-0.040041</td>\n",
       "      <td>-0.135922</td>\n",
       "      <td>0.419002</td>\n",
       "      <td>-0.230211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.602935</td>\n",
       "      <td>1.195531</td>\n",
       "      <td>0.175333</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>-0.229161</td>\n",
       "      <td>0.079211</td>\n",
       "      <td>-0.091262</td>\n",
       "      <td>0.411465</td>\n",
       "      <td>-0.269236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.066226</td>\n",
       "      <td>1.076442</td>\n",
       "      <td>0.146648</td>\n",
       "      <td>0.383198</td>\n",
       "      <td>0.168949</td>\n",
       "      <td>0.212592</td>\n",
       "      <td>-0.307593</td>\n",
       "      <td>0.453442</td>\n",
       "      <td>0.071817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.892321</td>\n",
       "      <td>1.163067</td>\n",
       "      <td>0.055728</td>\n",
       "      <td>0.329111</td>\n",
       "      <td>0.031941</td>\n",
       "      <td>0.232097</td>\n",
       "      <td>-0.360400</td>\n",
       "      <td>0.480115</td>\n",
       "      <td>-0.156419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.708854</td>\n",
       "      <td>1.330191</td>\n",
       "      <td>0.091693</td>\n",
       "      <td>0.124163</td>\n",
       "      <td>0.190836</td>\n",
       "      <td>0.156026</td>\n",
       "      <td>-0.565161</td>\n",
       "      <td>0.213646</td>\n",
       "      <td>-0.161548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.885708</td>\n",
       "      <td>1.356483</td>\n",
       "      <td>-0.013148</td>\n",
       "      <td>-0.042741</td>\n",
       "      <td>0.119489</td>\n",
       "      <td>0.125388</td>\n",
       "      <td>-0.182244</td>\n",
       "      <td>0.347712</td>\n",
       "      <td>-0.199627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.779591</td>\n",
       "      <td>0.992383</td>\n",
       "      <td>0.105303</td>\n",
       "      <td>0.172973</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.210199</td>\n",
       "      <td>-0.214643</td>\n",
       "      <td>0.332663</td>\n",
       "      <td>-0.143843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.690671</td>\n",
       "      <td>1.066703</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.184264</td>\n",
       "      <td>0.250915</td>\n",
       "      <td>0.140143</td>\n",
       "      <td>-0.419003</td>\n",
       "      <td>0.203223</td>\n",
       "      <td>-0.082123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     beta_0    beta_1    beta_2    beta_3    beta_4    beta_5    beta_6  \\\n",
       "0 -0.856691  1.207087  0.091872  0.059379  0.147427  0.236956 -0.616495   \n",
       "1 -1.120037  1.239479  0.110921  0.302168  0.096146  0.171504 -0.329141   \n",
       "2 -0.552030  1.249885  0.030376  0.103642  0.001009 -0.040041 -0.135922   \n",
       "3 -0.602935  1.195531  0.175333  0.024148 -0.229161  0.079211 -0.091262   \n",
       "4 -1.066226  1.076442  0.146648  0.383198  0.168949  0.212592 -0.307593   \n",
       "5 -0.892321  1.163067  0.055728  0.329111  0.031941  0.232097 -0.360400   \n",
       "6 -0.708854  1.330191  0.091693  0.124163  0.190836  0.156026 -0.565161   \n",
       "7 -0.885708  1.356483 -0.013148 -0.042741  0.119489  0.125388 -0.182244   \n",
       "8 -0.779591  0.992383  0.105303  0.172973  0.079200  0.210199 -0.214643   \n",
       "9 -0.690671  1.066703  0.022236  0.184264  0.250915  0.140143 -0.419003   \n",
       "\n",
       "     beta_7    beta_8  \n",
       "0  0.281108  0.129503  \n",
       "1  0.306554  0.025916  \n",
       "2  0.419002 -0.230211  \n",
       "3  0.411465 -0.269236  \n",
       "4  0.453442  0.071817  \n",
       "5  0.480115 -0.156419  \n",
       "6  0.213646 -0.161548  \n",
       "7  0.347712 -0.199627  \n",
       "8  0.332663 -0.143843  \n",
       "9  0.203223 -0.082123  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = (DataFrame(index =list(range(10)))\n",
    "    .reindex(columns = ['beta_{}'.format(i) for i in range(9)]))\n",
    "\n",
    "for i, training_samples, test_samples in crossvalidation_splits(data, data['y']):\n",
    "    train = data.iloc[training_samples]\n",
    "    clf_2.fit(train[features], train['y'])\n",
    "    result.loc[i, :] = coeff(clf_2).values\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Let melt the data and compute $95\\%$ confidence intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_0</td>\n",
       "      <td>-0.856691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_1</td>\n",
       "      <td>1.207087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_2</td>\n",
       "      <td>0.091872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_3</td>\n",
       "      <td>0.059379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>beta_4</td>\n",
       "      <td>0.147427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold coefficient     value\n",
       "0     0      beta_0 -0.856691\n",
       "1     0      beta_1  1.207087\n",
       "2     0      beta_2  0.091872\n",
       "3     0      beta_3  0.059379\n",
       "4     0      beta_4  0.147427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beta_0</td>\n",
       "      <td>-0.815506</td>\n",
       "      <td>0.185885</td>\n",
       "      <td>-0.991852</td>\n",
       "      <td>-0.639161</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta_1</td>\n",
       "      <td>1.187725</td>\n",
       "      <td>0.116214</td>\n",
       "      <td>1.077475</td>\n",
       "      <td>1.297975</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta_2</td>\n",
       "      <td>0.081696</td>\n",
       "      <td>0.058157</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.136869</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_3</td>\n",
       "      <td>0.164030</td>\n",
       "      <td>0.138791</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.295699</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beta_4</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>0.133160</td>\n",
       "      <td>-0.040651</td>\n",
       "      <td>0.212001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>beta_5</td>\n",
       "      <td>0.152408</td>\n",
       "      <td>0.084402</td>\n",
       "      <td>0.072337</td>\n",
       "      <td>0.232478</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>beta_6</td>\n",
       "      <td>-0.322187</td>\n",
       "      <td>0.175093</td>\n",
       "      <td>-0.488295</td>\n",
       "      <td>-0.156078</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beta_7</td>\n",
       "      <td>0.344893</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.253797</td>\n",
       "      <td>0.435988</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beta_8</td>\n",
       "      <td>-0.101577</td>\n",
       "      <td>0.134477</td>\n",
       "      <td>-0.229154</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coefficient      mean       std  lower_ci  upper_ci  significant\n",
       "0      beta_0 -0.815506  0.185885 -0.991852 -0.639161         True\n",
       "1      beta_1  1.187725  0.116214  1.077475  1.297975         True\n",
       "2      beta_2  0.081696  0.058157  0.026523  0.136869         True\n",
       "3      beta_3  0.164030  0.138791  0.032362  0.295699         True\n",
       "4      beta_4  0.085675  0.133160 -0.040651  0.212001        False\n",
       "5      beta_5  0.152408  0.084402  0.072337  0.232478         True\n",
       "6      beta_6 -0.322187  0.175093 -0.488295 -0.156078         True\n",
       "7      beta_7  0.344893  0.096023  0.253797  0.435988         True\n",
       "8      beta_8 -0.101577  0.134477 -0.229154  0.025999        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (DataFrame(result.stack(), columns = ['value'])\n",
    "      .reset_index()\n",
    "      .rename(columns = {'level_0':'fold', 'level_1':'coefficient'}))\n",
    "display(head(df))\n",
    "\n",
    "sdf = (df.groupby(['coefficient'])\n",
    "       .aggregate({'value': ['mean', 'std']})\n",
    "       .pipe(reset_column_index, 0)\n",
    "       .assign(lower_ci = lambda df: df['mean'] - 3 * df['std']/np.sqrt(10))\n",
    "       .assign(upper_ci = lambda df: df['mean'] + 3 * df['std']/np.sqrt(10))\n",
    "       .assign(significant = lambda df: np.sign(df['lower_ci'] * df['upper_ci']) == 1)\n",
    "       .reset_index())\n",
    "display(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223372029298441514)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = ggplot(df)\n",
    "p = p + geom_hline(yintercept = 0, color = 'red', linetype ='--')\n",
    "p = p + geom_boxplot(aes(x = 'coefficient', y = 'value'), fill = 'oldlace')\n",
    "p = p + scale_x_discrete(name = '', labels=[r'$\\beta_{}$'.format(i) for i in range(9)])\n",
    "p = p + scale_y_continuous(name = \"\", limits = (-1.5, 1.5))\n",
    "p.save('crossvalidation_parameter_variance_i.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223372029298847691)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = ggplot(sdf)\n",
    "p = p + geom_hline(yintercept = 0, color = 'red', linetype ='--', size = 1)\n",
    "p = p + geom_pointrange(aes(x = 'coefficient', ymin = 'lower_ci', y='mean', ymax = 'upper_ci', color = 'significant'), size=0.75)\n",
    "p = p + scale_x_discrete(name = '', labels=[r'$\\beta_{}$'.format(i) for i in range(9)])\n",
    "p = p + scale_y_continuous(name = \"\", limits = (-1.5, 1.5))\n",
    "p = p + scale_color_discrete(guide = False)\n",
    "p.save('crossvalidation_parameter_variance_ii.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Analysis of prediction stability (<font color='red'>3p</font>)\n",
    "\n",
    "Crossvalidation can be used to study the stability of a learning algorithm:\n",
    "\n",
    "* You can study how much do coefficients of you model vary.\n",
    "* You can study how fragile is your learning algorithm to noise.\n",
    "\n",
    "Lets explore these concepts by studing the stability of polynomial regression models $y\\sim x^2+x+1$ and $y\\sim x^8 + x^7 + \\cdots + x + 1$.\n",
    "\n",
    "* Stability of coefficients (<font color='red'>1p</font>) \n",
    "  * Fit these models on crossvalidation folds and observe regression coefficients by drawing corresponding boxplots. \n",
    "  * Study the mean and variance of individual model coefficients. Declare that a coefficient is insignificant and set it to zero when its mean is not more than 3 standard deviations away from the zero. \n",
    "  * Interpret the results. Are both models similar?\n",
    "  \n",
    "  \n",
    "* Stability of predictions (<font color='red'>1p</font>) \n",
    "  * Fit these models on crossvalidation folds.\n",
    "  * For each learned model compute prediction line in the interval $[-2,1]$.\n",
    "  * Draw a faceted plot with facets for models $y\\sim x^2+x+1$ and $y\\sim x^8 + x^7 + \\cdots + x + 1$.\n",
    "  * On each subplot plot individual prediction lines. Use `alpha=0.5` to make lines semi-transparent.\n",
    "  * Draw also average prediction line in red on the plot.\n",
    "\n",
    "\n",
    "* Stability against noise (<font color='red'>1p</font>) \n",
    "  * To study robustness against noise, you can add additional Gaussian noise to $y_i$ values of bootstrapped samples     and later estimate how much did mean square error increase as a consequence. \n",
    "  * The latter should estimate how sensitive is your method to random noise.\n",
    "  * Experiment with different scale values $\\sigma=0.001, 0.01, 0.1, 1$ and visualise results.\n",
    " \n",
    "  \n",
    "\n",
    "### Remarks\n",
    "* Use the following sampler `regr_sampler` as the data source. \n",
    "* Use [sklearn.linear_model.LinearRegression](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) together with \n",
    "[sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) to implement polynomial regression:\n",
    "  * First define additional columns $x_2=x^2, \\ldots, x_8=x^8$.\n",
    "  * Then use linear regression for find corresponding coefficients $\\beta_0,\\beta_1,\\ldots, \\beta_8$.\n",
    "* Use [numpy.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html) to sample the additional Gaussian noise needed in the last part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
