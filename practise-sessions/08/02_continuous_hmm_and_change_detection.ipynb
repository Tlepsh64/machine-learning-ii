{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous HMM and change detection\n",
    "\n",
    "Recall that in the HMM prectice session we tried to detect wet and try seasons of Singapore\n",
    "\n",
    "* [03_change_detection_with_hidden_markov_models.ipynb](../03/03_change_detection_with_hidden_markov_models.ipynb)\n",
    "\n",
    "but at that time we did not know how to fit model paramaters. The aim of this exercise session is to complete the task again but now with paramater fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple\n",
    "\n",
    "from tqdm import tnrange#, tqdm_notebook\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. E-step formulaes for clustering and HMM\n",
    "\n",
    "For the clustering we must assign weight for each character image by rescaling the likelihood matrix. More precisely let $(p_{ij})$ be the probabilities that the $i$th image belongs to the cluster $j$ then \n",
    "\\begin{align*}\n",
    " w_{ij} = \\frac{p_{ij}}{\\sum_{j} p_{ij}}\\enspace.\n",
    "\\end{align*}\n",
    "For the HMM we need to compute two marginal probabilities:\n",
    "* $\\gamma_{j}(i)$ probability that the $i$th internal state is $j$ given the observation vector and HMM parameters\n",
    "* $\\xi_{jk}(i)$ probability that the $i$th and $(i+1)$th internal states are $j$ and $k$ given the observation vector and HMM parameters.\n",
    "More formally\n",
    "\n",
    "\\begin{align*}\n",
    "\\gamma_{j}(i)&=\\Pr[x_i=j|\\boldsymbol{y},\\boldsymbol{\\Theta}]\\\\\n",
    "\\xi_{jk}(i)&=\\Pr[x_i=j, x_{i+1}=k|\\boldsymbol{y},\\boldsymbol{\\Theta}]\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. M-step formulaes for clustering and HMM\n",
    "\n",
    "For the clustering and HMM emission we can use gaussian mixtures discussed in the previous exercise session \n",
    "\n",
    "* [03_concepts_behind_expectation_maximisation_algorithm](../07/03_concepts_behind_expectation_maximisation_algorithm.ipynb)\n",
    "\n",
    "For single observation sequence, the HMM transition probabilities we can use formulae\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta_j&=\\gamma_{i}(1)\\\\\n",
    "\\alpha_{jk}&=\\frac{\\sum_{i} \\xi_{jk}(i)}{\\sum_i \\gamma_j(i)}\n",
    "\\end{align*}\n",
    "\n",
    "The generalisation to multiple observation sequences as in our problem is obvious -- we just compute sums over all observations and normalise appropriately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement the EM-algorithm  for the HMM with normal emissions (<font color='red'>3p</font>)\n",
    "\n",
    "Implement the weight computation for the HMM. The computation of $\\gamma_{j}(i)$ has been already done in the HMM exercise session, as this is a marginal state probability given all observations. For the weights $\\xi_{jk}(i)$ you need to define computation scheme that is analogous. Check the consistency of your derivations through the following formula\n",
    "\n",
    "\\begin{align*}\n",
    "  \\gamma_{j}(i)=\\sum_k\\xi_{ik}(i)\n",
    "\\end{align*}\n",
    "\n",
    "Implement the M-step by updating the parameters and then assemble the entire algorithm. Use simple 100 iterations as stopping criterion. Run the algorithm on the dataset and output model parameters.\n",
    "Redo the visual annotations by showing 4 types of state assignments as in the notebook \n",
    "[03_change_detection_with_hidden_markov_models.ipynb](../03/03_change_detection_with_hidden_markov_models.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Experiment with the model structure (<font color='red'>3p</font>)\n",
    "\n",
    "By defaul the EM-algorithm adjusts all model paramaters. Try different models:\n",
    "\n",
    "* model where transition matrix is fixed and you must learn only the emision distribution;\n",
    "* model where the number of states is three and all parameters are free;\n",
    "* model with cascading states described in the exercise 3.1 in the notebook  [03_change_detection_with_hidden_markov_models.ipynb](../03/03_change_detection_with_hidden_markov_models.ipynb). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
